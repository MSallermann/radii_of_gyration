import polars as pl
from pathlib import Path
import itertools
import json


configfile: "config.yml"


DATA_BASE = pl.read_parquet(config["database_file"])

with open("./samples.json", "rb") as f:
    SAMPLES = json.load(f)


# Function to get the plddts from the database
def get_plddts(wc):
    accession = SAMPLES[wc.sample]["accession"]
    return DATA_BASE.filter(pl.col("accession") == accession)["plddts"][0]


# Function to get the cif from the database
def get_cif(wc):
    accession = SAMPLES[wc.sample]["accession"]
    return DATA_BASE.filter(pl.col("accession") == accession)["cif_text"][0]


# sample wild card to temperature
def get_temp(wc):
    return SAMPLES[wc.sample]["temperature"]

# sample wild card to ionic strength
def get_ionic_strength(wc):
    return SAMPLES[wc.sample]["ionic_strength"]

# sample wild card to threshold
def get_threshold(wc):
    return SAMPLES[wc.sample]["threshold"]

def get_start_idx(wc):
    return SAMPLES[wc.sample].get("start_idx")

def get_end_idx(wc):
    return SAMPLES[wc.sample].get("end_idx")


N_STEPS = config["n_steps"]
TIMESTEP = config["timestep"]
MINIMUM_DOMAIN_LENGTH = config["minimum_domain_length"]
MINIMUM_IDR_LENGTH = config["minimum_idr_length"]
LAMMPS_BIN = config["lammps_binary"]
RG_SKIP = config["rg_skip"]

# geometric criterion (these are all optional)
MIN_PAE_CUTOFF = config.get("min_pae_cutoff")
MEAN_PAE_CUTOFF = config.get("mean_pae_cutoff")
MIN_DISTANCE_CUTOFF = config.get("min_distance_cutoff")
MAX_COORDINATION_CUTOFF = config.get("max_coordination_cutoff")
COORDINATION_DISTANCE_CUTOFF = config.get("coordination_distance_cutoff")

rule all:
    input:
        [f"results/aggregated_rg.csv" for sample in SAMPLES.keys()],


rule prepare_coarse_grained_inputs:
    localrule: True
    input:
        template_file=ancient(
            Path(workflow.source_path("templates/rg_script.lmp.jinja"))
        ),
    output:
        directory("results/lammps_files/{sample}"),
    params:
        temp=get_temp,
        ionic_strength=get_ionic_strength,
        n_steps=N_STEPS,
        timestep=TIMESTEP,
        threshold=get_threshold,
        minimum_domain_length=MINIMUM_DOMAIN_LENGTH,
        minimum_idr_length=MINIMUM_IDR_LENGTH,
        plddts=get_plddts,
        cif_text=get_cif,
        min_pae_cutoff = MIN_PAE_CUTOFF,
        mean_pae_cutoff = MEAN_PAE_CUTOFF,
        min_distance_cutoff = MIN_DISTANCE_CUTOFF,
        max_coordination_cutoff = MAX_COORDINATION_CUTOFF,
        coordination_distance_cutoff = COORDINATION_DISTANCE_CUTOFF,
        start_idx=get_start_idx,
        end_idx=get_end_idx

    script:
        workflow.source_path("scripts/coarse_grain.py")


rule run_lammps:
    input:
        "results/lammps_files/{sample}",
    output:
        folder=directory("results/lammps_runs/{sample}"),
        gyration="results/lammps_runs/{sample}/gyration.out",
    resources:
        nodes=1,
        n_tasks_per_node=1,
        slurm_out=lambda wc: f"results/lammps_files/{wc.sample}.out",
        slurm_err=lambda wc: f"results/lammps_files/{wc.sample}.err",
    shell:
        "cp -r {input}/* {output.folder}\n"
        "cd {output.folder}\n"
        f"{LAMMPS_BIN} -in script.lmp\n"


rule average_radius_of_gyration:
    localrule: True
    input:
        "results/lammps_runs/{sample}/gyration.out",
    output:
        rg_json="results/rg/{sample}/rg.json",
    params:
        n_skip=int(RG_SKIP),
    script:
        workflow.source_path("scripts/average_radius_of_gyration.py")


rule aggregate_rg:
    localrule: True
    input:
        [f"results/rg/{sample}/rg.json" for sample in SAMPLES.keys()],
    params:
        add_columns={
            "accession": [SAMPLES[sample]["accession"] for sample in SAMPLES.keys()],
            "threshold": [SAMPLES[sample]["threshold"] for sample in SAMPLES.keys()],
            "temperature": [
                SAMPLES[sample]["temperature"] for sample in SAMPLES.keys()
            ],
            "ionic_strength": [
                SAMPLES[sample]["ionic_strength"] for sample in SAMPLES.keys()
            ],
        },
        ignore_columns=["file"],
    output:
        "results/aggregated_rg.csv",
    script:
        workflow.source_path("scripts/aggregate_json.py")
